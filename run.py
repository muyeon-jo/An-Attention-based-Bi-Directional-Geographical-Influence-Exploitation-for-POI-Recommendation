from datetime import datetime
import numpy as np
import os
import datasets
from batches import *
from model import *
import time
import random
import validation as val
import torch.cuda
import torch
from save import save_experiment_result

class Args:
    def __init__(self):
        self.lr = 0.0001# learning rate            
        self.lamda = 1e-8# model regularization rate
        self.epochs = 40 # training epoches
        self.int_embed_size = 64 
        self.geo_embed_size = 64
        self.hidden_dim = 128 
        self.num_ng = 4 
        self.beta = 0.5
        self.areanum = 100

def train(train_matrix, test_positive, val_positive, dataset,args=Args()):

    now = datetime.now()
    model_directory = "./model/"+now.strftime('%Y-%m-%d %H_%M_%S')
    result_directory = "./result/"+now.strftime('%Y-%m-%d %H_%M_%S')
    if not os.path.exists(model_directory):
        os.makedirs(model_directory)
    if not os.path.exists(result_directory):
        os.makedirs(result_directory)
    max_recall = 0.0
    k_list=[5, 10, 15, 20, 25, 30]

    with open(result_directory+"/setting.txt","w") as setting_f:
        setting_f.write("lr:{}\n".format(str(args.lr)))
        setting_f.write("lamda:{}\n".format(str(args.lamda)))
        setting_f.write("epochs:{}\n".format(str(args.epochs)))
        setting_f.write("geo_dim:{}\n".format(str(args.geo_embed_size)))
        setting_f.write("int_dim:{}\n".format(str(args.int_embed_size)))
        setting_f.write("hidden_dim:{}\n".format(str(args.hidden_dim)))
        setting_f.write("num_ng:{}\n".format(str(args.num_ng)))
        setting_f.write("dataset:{}\n".format(str(dataset.directory_path)))

    num_users = dataset.user_num
    num_items = dataset.poi_num
    model = recommendation_model(num_items, args.int_embed_size, args.geo_embed_size,args.hidden_dim,0.5).to(DEVICE)

    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.lamda)
    for e in range(args.epochs):
        model.train()
        train_loss = 0.0
        start_time = int(time.time())

        idx = list(range(num_users))
        random.shuffle(idx)
        for buid in idx:
            optimizer.zero_grad()
            user_history , train_data, train_label= train_batch(train_matrix, num_items, buid, args.num_ng)
            temp = user_history.expand([len(train_label),len(user_history[0])])
            prediction = model(temp, train_data, dataset.nearPOI)
            loss = model.loss_func(prediction,train_label)
            train_loss += loss.item()
            loss.backward() # 역전파 및 그래디언트 계산
            optimizer.step() # 옵티마이저 업데이트
        end_time = int(time.time())
        print("Train Epoch: {}; time: {} sec; loss: {:.4f}".format(e+1, end_time-start_time,train_loss))
        if (e+1)%5 == 0:
            model.eval() 
            with torch.no_grad():
                start_time = int(time.time())
                precision_v, recall_v, hit_v, precision_t, recall_t, hit_t = val.validation(model,num_users,test_positive,val_positive,train_matrix,k_list,dataset.nearPOI)
                if(max_recall < recall_v[1]):
                    max_recall = recall_v[1]
                    torch.save(model, model_directory+"/model")
                    save_experiment_result(result_directory,[recall_t,precision_t,hit_t],k_list,e+1)
                end_time = int(time.time())
                print("eval time: {} sec".format(end_time-start_time))

def run(dataset,arg):
    train_matrix, test_positive, val_positive, place_coords = dataset.generate_data(0,args.areanum)
    print("train data generated")
    
    print("train start")
    train(train_matrix, test_positive, val_positive, dataset,arg)
if __name__ == '__main__':
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    seed=0
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

    args = Args()
    dataset_ = dataset_ = datasets.Dataset(3725,10768,"./data/Tokyo/")
    run(dataset_,args)